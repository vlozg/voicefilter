{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.virtualenvs/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils.hparams import HParam\n",
    "from datasets.get_dataset import get_dataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.audio import Audio\n",
    "\n",
    "from model.get_model import get_vfmodel, get_embedder, get_forward\n",
    "from loss.get_criterion import get_criterion\n",
    "\n",
    "from torch_mir_eval import bss_eval_sources\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "import json\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, range=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    im = ax.imshow(spectrogram, aspect='auto', origin='lower',\n",
    "                   interpolation='none')\n",
    "    if range:\n",
    "        im.set_clim(vmin=range[0], vmax=range[1])\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.ylabel('Channels')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plotly_spectrogram(spectrogram):\n",
    "    fig = px.imshow(spectrogram, aspect='auto', origin='lower',\n",
    "                    color_continuous_scale=\"Viridis\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_results/libri_test.json\", \"r\") as f:\n",
    "    test_record = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/voicefilter/utils/hparams.py:18: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "hp = HParam(\"config/default.yaml\")\n",
    "audio = Audio(hp[\"experiment\"])\n",
    "data_config = HParam(test_record[\"config\"])\n",
    "\n",
    "hp.experiment.use_cuda = False\n",
    "hp.experiment.dataset = data_config.experiment.dataset\n",
    "testset = get_dataset(hp, scheme=\"test\")\n",
    "df = testset.data\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_module(config_p, chkpt_p):\n",
    "    config = HParam(config_p)[\"experiment\"]\n",
    "    config.model.pretrained_chkpt = chkpt_p\n",
    "\n",
    "    # Init model, embedder, optim, criterion\n",
    "    _audio = Audio(config)\n",
    "    embedder = get_embedder(config, train=False, device=device)\n",
    "    model, _ = get_vfmodel(config, train=False, device=device)\n",
    "    train_forward, _ = get_forward(config)\n",
    "    criterion = get_criterion(config)\n",
    "\n",
    "\n",
    "    def inference(index):\n",
    "        sample = testset.get_item(index, _audio)\n",
    "        for key in [\"dvec_mel\", \"target_wav\", \"mixed_wav\", \"target_stft\", \"mixed_stft\", \"mixed_mag\", \"mixed_phase\", \"target_mag\", \"target_phase\"]:\n",
    "            sample[key] = sample[key].unsqueeze(0)\n",
    "        sample[\"dvec\"] = sample[\"dvec_mel\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            est_stft, _, loss = train_forward(model, embedder, sample, criterion, device)\n",
    "            target_wav = sample[\"target_wav\"]\n",
    "            est_stft = est_stft.detach().numpy()[0]\n",
    "            \n",
    "        est_mag, _ = _audio.stft2spec(est_stft)\n",
    "        est_wav = _audio._istft(est_stft.T, length=len(target_wav[0]))\n",
    "\n",
    "        fig = plotly_spectrogram(est_mag)\n",
    "\n",
    "        _est_wav = torch.from_numpy(est_wav).reshape(1, -1)\n",
    "        _target_wav = target_wav.reshape(1, -1)\n",
    "        \n",
    "        sdr,sir,sar,perm = bss_eval_sources(_target_wav,_est_wav,compute_permutation=True)\n",
    "\n",
    "        return {\n",
    "            \"sdr\": sdr.item(),\n",
    "            \"loss\": loss.mean().item(),\n",
    "            \"spec\": fig,\n",
    "            \"wav\": est_wav,\n",
    "        }\n",
    "\n",
    "    return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/voicefilter/utils/hparams.py:18: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "pse_big_inference = get_inference_module(test_record[\"PSE_DCCRN_big\"][\"config\"], test_record[\"PSE_DCCRN_big\"][\"chkpt\"])\n",
    "pse_inference = get_inference_module(test_record[\"PSE_DCCRN\"][\"config\"], test_record[\"PSE_DCCRN\"][\"chkpt\"])\n",
    "vf_inference = get_inference_module(\"config/test_vf.yaml\", \"chkpt/powlaw_loss_finetune/chkpt_178000.pt\")\n",
    "pse_re_inference = get_inference_module(\"config/pse_dccrn_re.yaml\", \"chkpt/pse_dccrn_re/chkpt_120000.pt\")\n",
    "pse_stft_big_inference = get_inference_module(\"config/pse_dccrn_stft_big.yaml\", \"chkpt/pse_dccrn_stft_big/chkpt_70000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def get_audio_file_b64(f):\n",
    "    enc = base64.b64encode(open(f, \"rb\").read())\n",
    "    return enc.decode()\n",
    "\n",
    "def get_audio_b64(w, sr=16000):\n",
    "    enc = base64.b64encode(IPython.display.Audio(w, rate=sr).data)\n",
    "    return enc.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_sample_div(w, title):\n",
    "    return html.Div([\n",
    "        html.H3(title),\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(w)}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        # dcc.Graph(figure=plotly_spectrogram(audio.wav2spec(w)[0].T))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash('Explore test result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "    \n",
    "        html.Div(children=[\n",
    "            html.H2(\"Dimensions\"),\n",
    "\n",
    "            html.Div(children=[\n",
    "                html.Div(children=[\n",
    "                    html.Label('X-axis'),\n",
    "                    dcc.Dropdown(df.columns, None, id=\"dim-x-axis\"),\n",
    "                ], style={'display': 'inline-block'}),\n",
    "\n",
    "                html.Div(children=[\n",
    "                    html.Br(),\n",
    "                    html.Label('Y-axis'),\n",
    "                    dcc.Dropdown(df.columns, None, id=\"dim-y-axis\"),\n",
    "                ], style={'display': 'inline-block'}),\n",
    "            ], style={'display': 'grid',\n",
    "                'grid-template-columns': '1fr 1fr',\n",
    "            }),\n",
    "\n",
    "            html.Br(),\n",
    "            html.Label('Color'),\n",
    "            dcc.Dropdown(df.columns, None, id=\"dim-color\"),\n",
    "\n",
    "            html.Br(),\n",
    "            html.Label('Size'),\n",
    "            dcc.Dropdown(df.columns, None, id=\"dim-size\"),\n",
    "        ], style={'padding': 10, 'flex': 1}),\n",
    "\n",
    "        html.Div(children=[\n",
    "            html.H2(\"Interactive plot\"),\n",
    "            dcc.Graph(id='scatter-plot')\n",
    "        ], style={'padding': 10, 'flex': 3}),\n",
    "\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(\"Sample\"),\n",
    "        html.Div(id=\"show-sample-area\", \n",
    "            style={'display': 'grid',\n",
    "                'grid-template-columns': '1fr 1fr',\n",
    "                'grid-template-rows': '1fr 1fr',\n",
    "            })\n",
    "    ]),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(\"Inference\"),\n",
    "        html.Button(id='inference-button-state', n_clicks=0, children='Run'),\n",
    "        html.H3(\"PSE-DCCRN\"),\n",
    "        html.Div(id=\"pse-dccrn-inference\"),\n",
    "        html.H3(\"PSE-DCCRN (big)\"),\n",
    "        html.Div(id=\"pse-dccrn-big-inference\"),\n",
    "        html.H3(\"PSE-DCCRN (STFT, big)\"),\n",
    "        html.Div(id=\"pse-dccrn-stft-big-inference\"),\n",
    "        html.H3(\"PSE-DCCRN (re-train)\"),\n",
    "        html.Div(id=\"pse-dccrn-re-inference\"),\n",
    "        html.H3(\"VoiceFilter\"),\n",
    "        html.Div(id=\"vf-inference\"),\n",
    "        # html.Audio(\n",
    "        #     src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "        #     controls=True\n",
    "        # ),\n",
    "        # dcc.Graph(figure=result[\"spec\"]),\n",
    "    ], style={'padding': 10}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('scatter-plot', 'figure'),\n",
    "    Input('dim-x-axis', 'value'),\n",
    "    Input('dim-y-axis', 'value'),\n",
    "    Input('dim-color', 'value'),\n",
    "    Input('dim-size', 'value'),\n",
    ")\n",
    "def update_plot_dims(x_axis, y_axis, color, size):\n",
    "    fig = px.scatter(df, x=x_axis, y=y_axis,\n",
    "                 size=size, color=color, hover_name=None,\n",
    "                 marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                 log_x=False, size_max=55)\n",
    "    fig.update_traces(customdata=df.index)\n",
    "    fig.update_layout(clickmode='event+select')\n",
    "    fig.update_layout(transition_duration=500)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('pse-dccrn-big-inference', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_inference_pd_big(n_clicks, clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    result = pse_big_inference(idx)\n",
    "    return [\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        dcc.Graph(figure=result[\"spec\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('pse-dccrn-inference', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_inference_pd(n_clicks, clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    result = pse_inference(idx)\n",
    "    return [\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        dcc.Graph(figure=result[\"spec\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('pse-dccrn-re-inference', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_inference_pdr(n_clicks, clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    result = pse_re_inference(idx)\n",
    "    return [\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        dcc.Graph(figure=result[\"spec\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('pse-dccrn-stft-big-inference', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_inference_pdsb(n_clicks, clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    result = pse_stft_big_inference(idx)\n",
    "    return [\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        dcc.Graph(figure=result[\"spec\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('vf-inference', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_inference_vf(n_clicks, clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    result = vf_inference(idx)\n",
    "    return [\n",
    "        html.Audio(\n",
    "            src=f\"data:audio/mpeg;base64,{get_audio_b64(result['wav'])}\",\n",
    "            controls=True\n",
    "        ),\n",
    "        dcc.Graph(figure=result[\"spec\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('show-sample-area', 'children'),\n",
    "    Input('scatter-plot', 'clickData'),\n",
    ")\n",
    "def show_sample(clickData):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    sample = testset[idx]\n",
    "    return [\n",
    "        audio_sample_div(sample['mixed_wav'].numpy(), \"Mixed audio\"),\n",
    "        audio_sample_div(sample['dvec_wav'], \"Reference audio\"),\n",
    "        audio_sample_div(sample['target_wav'].numpy(), \"Target audio\"),\n",
    "        audio_sample_div(sample['interf_wav'].numpy(), \"Interference audio\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# Run app and display result inline in the notebook\n",
    "# app.run_server(mode='inline')\n",
    "app.run_server()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed27c33f293ca8c3697f2b328444ff97f02b44e95d63e9588b837d1a5300422"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
