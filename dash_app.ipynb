{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils.hparams import HParam, Dotdict\n",
    "from datasets.get_dataset import get_dataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.audio import Audio\n",
    "import librosa\n",
    "\n",
    "from model.get_model import get_vfmodel, get_embedder, get_forward\n",
    "from loss.get_criterion import get_criterion\n",
    "\n",
    "from torch_mir_eval import bss_eval_sources\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, State, dash_table, Dash\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech\n",
    "import io\n",
    "\n",
    "\n",
    "def transcribe_file(speech_file, language=\"vi-VN\"):\n",
    "    \"\"\"Transcribe the given audio file.\"\"\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=language,\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "\n",
    "    return response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# a, _ = librosa.load(\"datasets/VinBigdata/speakers/Bongnt_hall_2212/vinfast-vsmart-000004993-Bongnt_hall_2212-HaNoi-MienBac-1960-nu-vinfast-vsmart-1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(\"datasets/VinBigdata/speakers/Bongnt_hall_2212/vinfast-vsmart-000004993-Bongnt_hall_2212-HaNoi-MienBac-1960-nu-vinfast-vsmart-1.wav\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets/LibriSpeech/dev-clean/84/121123/84-121123-0000.txt\", \"r\") as f:\n",
    "#     t = f.read()\n",
    "# t.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embedder detail purpose\n",
    "# embedder_pt = torch.load(\"chkpt/power_law_zalo_embedder/chkpt_180000.pt\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, range=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    im = ax.imshow(spectrogram, aspect='auto', origin='lower',\n",
    "                   interpolation='none')\n",
    "    if range:\n",
    "        im.set_clim(vmin=range[0], vmax=range[1])\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.ylabel('Channels')\n",
    "\n",
    "    buf = io.BytesIO() # in-memory files\n",
    "    plt.savefig(buf, format = \"png\") # save to the above file object\n",
    "    plt.close()\n",
    "\n",
    "    return buf.getbuffer()\n",
    "\n",
    "def plotly_spectrogram(spectrogram):\n",
    "    fig = px.imshow(spectrogram, aspect='auto', origin='lower',\n",
    "                    color_continuous_scale=\"Viridis\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_module(config_p, chkpt_p, device):\n",
    "    config = HParam(config_p)[\"experiment\"]\n",
    "    config.model.pretrained_chkpt = chkpt_p\n",
    "\n",
    "    # Init model, embedder, optim, criterion\n",
    "    _audio = Audio(config)\n",
    "    embedder = get_embedder(config, train=False, device=device)\n",
    "    model, _ = get_vfmodel(config, train=False, device=device)\n",
    "    train_forward, inference_forward = get_forward(config)\n",
    "    criterion = get_criterion(config)\n",
    "\n",
    "\n",
    "    def inference(testset, index):\n",
    "        sample = testset.get_item(index, _audio)\n",
    "        for key in [\"dvec_mel\", \"target_wav\", \"mixed_wav\", \"target_stft\", \"mixed_stft\", \"mixed_mag\", \"mixed_phase\", \"target_mag\", \"target_phase\"]:\n",
    "            sample[key] = sample[key].unsqueeze(0)\n",
    "        sample[\"dvec\"] = sample[\"dvec_mel\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            est_stft, _, loss = train_forward(model, embedder, sample, criterion, device)\n",
    "            target_wav = sample[\"target_wav\"]\n",
    "            est_stft = est_stft.detach().numpy()[0]\n",
    "            \n",
    "        est_mag, _ = _audio.stft2spec(est_stft)\n",
    "        est_wav = _audio._istft(est_stft.T, length=len(target_wav[0]))\n",
    "\n",
    "        _est_wav = torch.from_numpy(est_wav).reshape(1, -1)\n",
    "        _target_wav = target_wav.reshape(1, -1)\n",
    "        \n",
    "        sdr,sir,sar,perm = bss_eval_sources(_target_wav,_est_wav,compute_permutation=False)\n",
    "\n",
    "        return {\n",
    "            \"sdr\": sdr.item(),\n",
    "            \"loss\": loss.mean().item(),\n",
    "            \"spec\": est_mag,\n",
    "            \"wav\": est_wav,\n",
    "        }\n",
    "\n",
    "    return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload model\n",
    "model_df = pd.read_csv(\"model_list.csv\")\n",
    "device = \"cpu\"\n",
    "\n",
    "print(\"Start importing model from model list\")\n",
    "\n",
    "model_dict = {}\n",
    "for _, r in model_df.iterrows():\n",
    "    config, chkpt, _ = r\n",
    "    try:\n",
    "        model = get_inference_module(config, chkpt, device)\n",
    "        model_dict[(config, chkpt)] = model\n",
    "    except:\n",
    "        print(\"Failed with model \" + config)\n",
    "\n",
    "print(\"Complete\")\n",
    "\n",
    "\n",
    "def load_test_record(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        test_record = json.load(f)\n",
    "\n",
    "    data_config = Dotdict(test_record[\"config\"])\n",
    "    hp.experiment.dataset = data_config.experiment.dataset\n",
    "    testset = get_dataset(hp, scheme=\"test\")\n",
    "\n",
    "    test_record.pop(\"data\")\n",
    "    test_record.pop(\"config\")\n",
    "\n",
    "    dim_sample = testset.data\n",
    "    if test_record.get(\"info\") is not None:\n",
    "        data_info = test_record.pop(\"info\")\n",
    "        dim_sample = dim_sample.join(pd.DataFrame(data_info))\n",
    "        \n",
    "    dim_sample = dim_sample.reset_index()\n",
    "\n",
    "    for e in test_record.keys():\n",
    "        if test_record[e].get(\"metrics\") is None:\n",
    "            continue\n",
    "        for m in test_record[e][\"metrics\"].keys():\n",
    "            if not os.path.isfile(test_record[e][\"metrics\"][m]):\n",
    "                print(f\"Metrics {m} in experiment {e} is missing.\")\n",
    "            else:\n",
    "                with open(test_record[e][\"metrics\"][m], \"r\") as f:\n",
    "                    result = json.load(f)\n",
    "                test_record[e][\"metrics\"][m] = result\n",
    "\n",
    "    test_record_df = pd.DataFrame(test_record).transpose().reset_index().rename(columns={\"index\": \"experiment\"})\n",
    "    fact_result = pd.concat([pd.DataFrame({\"experiment\": row[\"experiment\"], **row[\"metrics\"]}) for _, row in test_record_df.iterrows()])\n",
    "    dim_test = test_record_df.drop(\"metrics\", axis=1)\n",
    "    del test_record_df\n",
    "\n",
    "    df = fact_result.join(dim_sample).merge(dim_test, on=\"experiment\")\n",
    "\n",
    "    if \"output_dir\" in df.columns:\n",
    "        df[\"output_enhance_dir\"] = df[\"output_dir\"]+\"/\"+df[\"index\"].astype(str)+\".wav\"\n",
    "        df[\"output_asr_dir\"] = df[\"output_dir\"]+\"/\"+df[\"index\"].astype(str)+\"_asr.json\"\n",
    "\n",
    "    models = {}\n",
    "    for m in test_record.keys():\n",
    "        if \"dataset_info\" in m:\n",
    "            continue\n",
    "        try:\n",
    "            models[m] = model_dict.get((test_record[m][\"config\"], test_record[m][\"chkpt\"]))\n",
    "        except:\n",
    "            print(\"Failed with model \" + m)\n",
    "    \n",
    "    return df, models, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HParam(\"config/default.yaml\")\n",
    "hp.experiment.use_cuda = False\n",
    "audio = Audio(hp[\"experiment\"])\n",
    "\n",
    "test_records = list(glob.glob(\"test_results/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def get_audio_file_b64(f):\n",
    "    enc = base64.b64encode(open(f, \"rb\").read())\n",
    "    return enc.decode()\n",
    "\n",
    "def get_audio_b64(w, sr=16000):\n",
    "    # w can be wav array or path\n",
    "    enc = base64.b64encode(IPython.display.Audio(w, rate=sr, normalize=False).data)\n",
    "    return enc.decode()\n",
    "\n",
    "def get_svg_b64(buf):\n",
    "    enc = base64.b64encode(buf)\n",
    "    return enc.decode()\n",
    "\n",
    "def get_audio_block_from_wav(w):\n",
    "    return html.Audio(\n",
    "        src=f\"data:audio/mpeg;base64,{get_audio_b64(w)}\",\n",
    "        controls=True\n",
    "    )\n",
    "\n",
    "def get_audio_block_from_file(p):\n",
    "    return html.Audio(\n",
    "        src=f\"data:audio/mpeg;base64,{get_audio_b64(p)}\",\n",
    "        controls=True\n",
    "    )\n",
    "\n",
    "def get_spectrogram_img(spec):\n",
    "    return html.Img(src=f\"data:image/png;base64,{get_svg_b64(plot_spectrogram(spec))}\")\n",
    "\n",
    "def get_spectrogram_img_from_file(p, sr=16000):\n",
    "    #w = IPython.display.Audio(p, rate=sr, normalize=False).data\n",
    "    w, _ = librosa.load(p, sr)\n",
    "    est_mag, _ = audio.wav2spec(w)\n",
    "    return get_spectrogram_img(est_mag.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_sample_div(w, title):\n",
    "    spec = audio.wav2spec(w)[0].T\n",
    "    return html.Div([\n",
    "        html.H3(title),\n",
    "        get_audio_block_from_wav(w),\n",
    "        get_spectrogram_img(spec)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _, _ = load_test_record(\"test_results/libri_gg_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "df = None\n",
    "models = None\n",
    "testset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = Dash('Explore test result', requests_pathname_prefix='/dashboard/')\n",
    "app = JupyterDash('Explore test result', requests_pathname_prefix='/dashboard/')\n",
    "# app = JupyterDash('Explore test result')\n",
    "# app.css.config.serve_locally = False\n",
    "# app.scripts.config.serve_locally = True\n",
    "# app.css.config.serve_locally = True\n",
    "\n",
    "app.css.append_css({\n",
    "    'external_url': 'https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "    html.P(id=\"t_current_test_record\", style={\"hidden\": True}),\n",
    "    \n",
    "    html.Div(children=[\n",
    "            \n",
    "        html.Div(children=[\n",
    "            html.Div(children=[\n",
    "                html.Label('Test record'),\n",
    "                dcc.Dropdown(test_records, id=\"test-record\"),\n",
    "            ]),\n",
    "\n",
    "            html.H2(\"Dimensions\"),\n",
    "\n",
    "            dcc.Loading(\n",
    "                children=[html.Div(children=[\n",
    "                    html.Div(children=[\n",
    "                        html.Label('X-axis'),\n",
    "                        dcc.Dropdown(id=\"dim-x-axis\"),\n",
    "                    ], style={'display': 'inline-block'}),\n",
    "\n",
    "                    html.Div(children=[\n",
    "                        html.Label('Y-axis'),\n",
    "                        dcc.Dropdown(id=\"dim-y-axis\"),\n",
    "                    ], style={'display': 'inline-block'}),\n",
    "                ], style={'display': 'grid',\n",
    "                    'grid-template-columns': '1fr 1fr',\n",
    "                }),\n",
    "\n",
    "                html.Label('Color'),\n",
    "                dcc.Dropdown(id=\"dim-color\"),\n",
    "\n",
    "                html.Label('Size'),\n",
    "                dcc.Dropdown(id=\"dim-size\"),\n",
    "\n",
    "                html.H2(\"Filter\"),\n",
    "                html.Label('Experiment'),\n",
    "                dcc.Dropdown(id=\"filter-exp\", multi=True),\n",
    "                ], fullscreen=True, type=\"cube\"\n",
    "            ),\n",
    "        ], style={'padding': 10, 'flex': 1}),\n",
    "\n",
    "\n",
    "        html.Div(children=[\n",
    "            html.H2(\"Interactive plot\"),\n",
    "            dcc.RadioItems([\"Scatter\", \"Histogram\", \"Box plot\"], \"Histogram\", id=\"plot-type\"),\n",
    "            dcc.Loading(\n",
    "                children=dcc.Graph(id='main-plot'),\n",
    "                type=\"graph\",\n",
    "            )\n",
    "            # dcc.Graph(id='hist-plot')\n",
    "        ], style={'padding': 10, 'flex': 3}),\n",
    "\n",
    "\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "    \n",
    "    html.Div(children=[\n",
    "        html.H2(\"Statistic\"),\n",
    "        dcc.Loading(\n",
    "            children=dash_table.DataTable(id=\"statistic-table\", \n",
    "                merge_duplicate_headers=True, export_format=\"csv\",\n",
    "                fixed_columns={'headers': True, 'data': 1}, style_table={'minWidth': '100%'}\n",
    "            ),\n",
    "            type=\"dot\",\n",
    "        ),\n",
    "    ], style={'padding': 10}),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(\"Raw table\"),\n",
    "        dcc.Loading(\n",
    "            children=dash_table.DataTable(id=\"raw-table\", \n",
    "                merge_duplicate_headers=True, export_format=\"csv\",\n",
    "                fixed_columns={'headers': True}, style_table={'minWidth': '100%'},\n",
    "                page_current=0,\n",
    "                page_size=5,\n",
    "                page_action='native',\n",
    "                filter_action='custom',\n",
    "                filter_query=''\n",
    "            ),\n",
    "            type=\"dot\",\n",
    "        ),\n",
    "    ], style={'padding': 10}),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(\"Sample\"),\n",
    "        dcc.Loading(\n",
    "            children=\n",
    "            [\n",
    "                html.Div(id=\"sample-statistic-table\"),\n",
    "                html.Div(id=\"show-sample-area\", \n",
    "                    style={'display': 'grid',\n",
    "                        'grid-template-columns': '1fr 1fr',\n",
    "                        'grid-template-rows': '1fr 1fr',\n",
    "                    }),\n",
    "            ],\n",
    "            type=\"dot\"\n",
    "        ),\n",
    "    ], style={'padding': 10}),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(\"Inference\"),\n",
    "        html.Button(id='inference-button-state', n_clicks=0, children='Run', className=\"btn btn-primary\"),\n",
    "        dcc.Loading(children=html.Div(id=\"inference-area\"), type=\"dot\"),\n",
    "    ], style={'padding': 10}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('dim-x-axis', 'options'),\n",
    "    Output('dim-y-axis', 'options'),\n",
    "    Output('dim-color', 'options'),\n",
    "    Output('dim-size', 'options'),\n",
    "    Output('filter-exp', 'options'),\n",
    "    Output(\"t_current_test_record\", \"value\"),\n",
    "    Input('test-record', 'value'),\n",
    ")\n",
    "def change_test_record(test_record_path):\n",
    "    global df\n",
    "    global models\n",
    "    global testset\n",
    "    if test_record_path is not None:\n",
    "        _df, _models, _testset = load_test_record(test_record_path)\n",
    "        df = _df\n",
    "        models = _models\n",
    "        testset = _testset\n",
    "        return df.columns, df.columns, df.columns, df.columns, df[\"experiment\"].drop_duplicates(), test_record_path\n",
    "    else:\n",
    "        return tuple([[]]*5), \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('raw-table', 'columns'),\n",
    "    Input('t_current_test_record', 'value'),\n",
    ")\n",
    "def change_test_record_raw_tables(_):\n",
    "    return [{\"name\": i, \"id\": i, \"hideable\": True} for i in sorted(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                # word operators need spaces after them in the filter string,\n",
    "                # but we don't want these later\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n",
    "\n",
    "@app.callback(\n",
    "    Output('raw-table', 'data'),\n",
    "    Input('raw-table', \"page_current\"),\n",
    "    Input('raw-table', \"page_size\"),\n",
    "    Input('raw-table', \"filter_query\"),\n",
    "    Input('raw-table', 'columns'),\n",
    ")\n",
    "def update_table(page_current,page_size, filter, _):\n",
    "    print(filter)\n",
    "    filtering_expressions = filter.split(' && ')\n",
    "\n",
    "    dff = df\n",
    "    for filter_part in filtering_expressions:\n",
    "        col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "\n",
    "        if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "            # these operators match pandas series operator method names\n",
    "            dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "        elif operator == 'contains':\n",
    "            dff = dff.loc[dff[col_name].str.contains(filter_value)]\n",
    "        elif operator == 'datestartswith':\n",
    "            # this is a simplification of the front-end filtering logic,\n",
    "            # only works with complete fields in standard format\n",
    "            dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "\n",
    "    return dff.to_dict('records')\n",
    "    # .iloc[\n",
    "    #     page_current*page_size:(page_current+ 1)*page_size\n",
    "    # ].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('main-plot', 'figure'),\n",
    "    Input('plot-type', 'value'),\n",
    "    Input('dim-x-axis', 'value'),\n",
    "    Input('dim-y-axis', 'value'),\n",
    "    Input('dim-color', 'value'),\n",
    "    Input('dim-size', 'value'),\n",
    "    Input('filter-exp', 'value'),\n",
    "    Input('test-record', 'value'),\n",
    ")\n",
    "def update_plot_dims(plot_type, x_axis, y_axis, color, size, exp_filtered, _):\n",
    "    if df is None:\n",
    "        return px.scatter()\n",
    "        \n",
    "    if exp_filtered is not None:\n",
    "        _data = df[df[\"experiment\"].isin(exp_filtered)]\n",
    "    else:\n",
    "        _data = df\n",
    "    if plot_type == \"Scatter\":\n",
    "        fig = px.scatter(_data, x=x_axis, y=y_axis,\n",
    "                    size=size, color=color, hover_name=None,\n",
    "                    marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                    log_x=False, size_max=55)\n",
    "    elif plot_type == \"Histogram\":\n",
    "        fig = px.histogram(_data, x=x_axis, y=y_axis,\n",
    "                    color=color, hover_name=None,\n",
    "                    log_x=False)\n",
    "        fig.update_layout(barmode='overlay')\n",
    "        # Reduce opacity to see both histograms\n",
    "        fig.update_traces(opacity=0.75)\n",
    "    elif plot_type == \"Box plot\":\n",
    "        fig = px.box(_data, x=x_axis, y=y_axis,\n",
    "                    color=color, hover_name=None,\n",
    "                    log_x=False)\n",
    "\n",
    "    fig.update_traces(customdata=df[\"index\"])\n",
    "    fig.update_layout(clickmode='event+select')\n",
    "    fig.update_layout(transition_duration=500)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('statistic-table', 'data'),\n",
    "    Output('statistic-table', 'columns'),\n",
    "    Input('filter-exp', 'value'),\n",
    "    Input('test-record', 'value'),\n",
    ")\n",
    "def update_stat_table(exp_filtered, _):\n",
    "    \n",
    "    if exp_filtered is not None or exp_filtered is not []:\n",
    "        _data = df[df[\"experiment\"].isin(exp_filtered)]\n",
    "    else:\n",
    "        _data = df\n",
    "\n",
    "    _tab = []\n",
    "    _col = {}\n",
    "    for row in _data.groupby(\"experiment\").describe().reset_index().to_dict(\"records\"):\n",
    "        t = {}\n",
    "        for key, value in row.items():\n",
    "            col_idx = \"_\".join(key) \n",
    "            t[col_idx] = value\n",
    "            _col[col_idx] = list(key)\n",
    "        _tab.append(t)\n",
    "    \n",
    "    return _tab, [{\"name\": v, \"id\": k, \"hideable\": True} for k, v in _col.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('inference-area', 'children'),\n",
    "    Input('inference-button-state', 'n_clicks'),\n",
    "    State('main-plot', 'clickData'),\n",
    "    State('filter-exp', 'value'),\n",
    "    Input('test-record', 'value'),\n",
    ")\n",
    "def show_inference(n_clicks, clickData, exp_filtered, _):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from scatter plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "\n",
    "    # if exp_filtered is None or exp_filtered is not []:\n",
    "    if True:\n",
    "        exp_filtered = df[\"experiment\"].drop_duplicates()\n",
    "\n",
    "    block = []\n",
    "    for e in exp_filtered:\n",
    "        if \"dataset_info\" in e: continue\n",
    "        sample = df[(df[\"index\"] == idx) & (df[\"experiment\"] == e)].iloc[0]\n",
    "        asr_pred = \"(Not available)\"\n",
    "        asr_conf = \"(Not available)\"\n",
    "\n",
    "        if os.path.isfile(sample[\"output_asr_dir\"]):\n",
    "            with open(sample[\"output_asr_dir\"], \"r\") as f:\n",
    "                t = json.load(f)\n",
    "                asr_pred = t[\"transcript\"]\n",
    "                asr_conf = t[\"confidence\"]\n",
    "\n",
    "        # result = models[e](testset, idx)\n",
    "        block += [\n",
    "            html.H3(f\"Experiment: {e}\"),\n",
    "            html.Div(children=[\n",
    "                get_audio_block_from_file(sample[\"output_enhance_dir\"]),\n",
    "                get_spectrogram_img_from_file(sample[\"output_enhance_dir\"])\n",
    "            ],id=f\"{e}-inference\"),\n",
    "            html.P(f\"ASR inference: {asr_pred}\"),\n",
    "            html.P(f\"ASR confidence: {asr_conf}\")\n",
    "        ]\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('show-sample-area', 'children'),\n",
    "    Output('sample-statistic-table', 'children'),\n",
    "    Input('main-plot', 'clickData'),\n",
    "    State('filter-exp', 'value'),\n",
    "    Input('test-record', 'value'),\n",
    ")\n",
    "def show_sample(clickData, exp_filtered, _):\n",
    "    if clickData is None:\n",
    "        return [\n",
    "        \"Please select a data point from interative plot first to see the sample detail.\"\n",
    "    ]\n",
    "\n",
    "    if exp_filtered is None or exp_filtered is not []:\n",
    "        exp_filtered = df[\"experiment\"].drop_duplicates()\n",
    "\n",
    "    idx = clickData[\"points\"][0][\"customdata\"]\n",
    "    sample = testset[idx]\n",
    "    sample_df = df[(df[\"index\"] == idx) & (df[\"experiment\"].isin(exp_filtered))]\n",
    "\n",
    "    try:\n",
    "        sample['mixed_wav'] = sample['mixed_wav'].numpy()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        sample['target_wav'] = sample['target_wav'].numpy()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return [\n",
    "        audio_sample_div(sample['mixed_wav'], \"Mixed audio\"),\n",
    "        audio_sample_div(sample['dvec_wav'], \"Reference audio\"),\n",
    "        audio_sample_div(sample['target_wav'], \"Target audio\"),\n",
    "        # audio_sample_div(sample['interf_wav'], \"Interference audio\"),\n",
    "    ], [\n",
    "        html.Div(dash_table.DataTable(\n",
    "            sample_df.to_dict(\"records\"),\n",
    "            [{\"name\": i, \"id\": i} for i in sample_df.columns],\n",
    "            fixed_columns={'headers': True, 'data': 1}, style_table={'minWidth': '100%'},\n",
    "            export_format=\"csv\"\n",
    "        )),\n",
    "        html.Div([\n",
    "            html.H5(\"Data point index: \"),\n",
    "            html.P(idx)\n",
    "        ]),\n",
    "        html.Div([\n",
    "            html.H5(\"Prompt: \"),\n",
    "            html.P(sample[\"target_text\"])\n",
    "        ]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run app and display result inline in the notebook\n",
    "# app.run_server(mode='inline')\n",
    "app.run_server(port=8050)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
