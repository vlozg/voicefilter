experiment:
  name: "VFRaw_Test_Vivos"
  clean_rerun: True # Delete old logs and chkpt if true
  use_cuda: True
  
  dataset:
    name: "generate"
    train:
      file_path: "datasets/VivosGenerate_train.csv"
      detail: ["vivos-train"]
      audio_len: 3.0
      size: 500000
    eval: 
      file_path: "datasets/VivosGenerate_eval.csv"
      detail: ["vivos-test"]
      audio_len: 3.0
      size: 100
    test:
      file_path: "datasets/VivosGenerate_test.csv"
      detail: ["vivos-test"]
      audio_len: # varying audio length
      size: 10000
  
  model:
    name: "voicefilter"
    pretrained_chkpt: "chkpt/powlaw_loss_finetune/chkpt_178000.pt"
    resume_from_chkpt: False
    input_dim:  # 8*audio.num_freq + embedder.emb_dim, will get computed in get_model.py
    lstm_dim: 400
    fc1_dim: 600
    fc2_dim: 601 # num_freq
    bidirection: True

  loss_function: "power_law_compressed"

  train:
    batch_size: 6
    num_workers: 6
    grad_accumulate: 8
    optimizer: "adam"
    optimizer_param: 
      lr: 0.005
    max_step: 500000
    summary_interval: 1
    checkpoint_interval: 5000
  
  embedder: # d-vector embedder. don"t fix it!
    pretrained_chkpt: "embedder.pt"
    num_mels: 40
    n_fft: 512
    emb_dim: 256
    lstm_hidden: 768
    lstm_layers: 3
    window: 80
    stride: 40
  
  audio:
    n_fft: 1200
    num_freq: 601 # n_fft//2 + 1
    sample_rate: 16000
    hop_length: 160
    win_length: 400
    min_level_db: -100.0
    ref_level_db: 20.0
    preemphasis: 0.97
    power: 0.30

---
env:
  base_dir: "."
  data:
    libri_dir: "datasets/LibriSpeech"
    vivos_dir: "datasets/VIVOS/vivos"
    vctk_dir: "datasets/VCTK-Corpus"
    voxceleb1_dir: "datasets/VoxCeleb1"
    voxceleb2_dir: "datasets/VoxCeleb2"
    vin_dir: "datasets/VinBigdata"
    zalo_dir: "datasets/ZaloAI2020"

  log:
    chkpt_dir: "chkpt"
    log_dir: "logs"