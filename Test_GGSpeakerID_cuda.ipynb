{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed6be7b",
   "metadata": {},
   "source": [
    "# Import libraries & parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82b69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import json\n",
    "\n",
    "from utils.audio import Audio\n",
    "from utils.hparams import HParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af84b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf3d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hparams import HParam\n",
    "from datasets.dataloader import create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ff3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils.adabound import AdaBound\n",
    "from utils.power_law_loss import PowerLawCompLoss\n",
    "from model.model import VoiceFilter\n",
    "from model.embedder import SpeechEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a49c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/voicefilter/utils/hparams.py:18: YAMLLoadWarning: calling yaml.load_all() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  for doc in docs:\n"
     ]
    }
   ],
   "source": [
    "hp = HParam(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b99fb",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060b484",
   "metadata": {},
   "source": [
    "Create testloader and get first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4534eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader_vn = create_dataloader(hp, \"generate\", dataset_detail=[\"vin\", \"zalo-train\", \"zalo-test\"], scheme=\"test_cuda\", size=5000)\n",
    "testloader_lb = create_dataloader(hp, \"generate\", dataset_detail=[\"librispeech-test\"], scheme=\"test_cuda\", size=5000)\n",
    "testloader_gg = create_dataloader(hp, \"gg\", dataset_detail=\"test\", scheme=\"test_cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31581ec",
   "metadata": {},
   "source": [
    "Audio is an abstract class that help simplify many operation on a single audio file like convert to mel, waveform to mel or mel to waveform,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4747dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio(hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba167c",
   "metadata": {},
   "source": [
    "Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86698b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "embedder_pt = torch.load(\"embedder.pt\", device)\n",
    "embedder = SpeechEmbedder(hp)\n",
    "embedder.load_state_dict(embedder_pt)\n",
    "embedder = embedder.cuda()\n",
    "embedder.eval()\n",
    "\n",
    "# Power-law compressed loss\n",
    "model = VoiceFilter(hp)\n",
    "checkpoint = torch.load(\"chkpt/powlaw_loss/chkpt_168000.pt\", device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# First try (MSE loss)\n",
    "model_0 = VoiceFilter(hp)\n",
    "checkpoint = torch.load(\"chkpt/new_dataloader/chkpt_108000.pt\", device)\n",
    "model_0.load_state_dict(checkpoint['model'])\n",
    "model_0 = model_0.cuda()\n",
    "model_0.eval()\n",
    "\n",
    "# MSE ver 48k (ms.Tam)\n",
    "model_t = VoiceFilter(hp)\n",
    "checkpoint = torch.load(\"chkpt/mstam_mse/chkpt_48000.pt\", device)\n",
    "model_t.load_state_dict(checkpoint['model'])\n",
    "model_t = model_t.cuda()\n",
    "model_t.eval()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5300",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d10078",
   "metadata": {},
   "source": [
    "Inference function for power-law compressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fff6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_forward(model, batch):\n",
    "    criterion = PowerLawCompLoss()\n",
    "    dvec_mels, target_mag, _, mixed_mag, mixed_phase, target_stft, mixed_stft, target_wavs, mixed_wavs = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dvec_list = list()\n",
    "        for mel in dvec_mels:\n",
    "            mel = mel.cuda()\n",
    "            dvec = embedder(mel)\n",
    "            dvec_list.append(dvec)\n",
    "        dvec = torch.stack(dvec_list, dim=0)\n",
    "        target_stft = target_stft.cuda()\n",
    "        mixed_stft = mixed_stft.cuda()\n",
    "        \n",
    "\n",
    "        est_mask = model(torch.pow(mixed_stft.abs(), 0.3), dvec)\n",
    "        loss = criterion(est_mask, mixed_stft, target_stft).item()\n",
    "        \n",
    "        est_mask = torch.pow(est_mask, 10/3)\n",
    "        est_stft = mixed_stft * est_mask\n",
    "        est_stft = est_stft.cpu().numpy()\n",
    "\n",
    "    sdrs = []\n",
    "    sdrs_before = []\n",
    "    for est_stft_, target_wav, mixed_wav in zip(est_stft, target_wavs, mixed_wavs):\n",
    "        est_wav = audio._istft(est_stft_.T, length=len(target_wav))\n",
    "        sdrs_before.append(bss_eval_sources(target_wav, mixed_wav, False)[0][0])\n",
    "        sdrs.append(bss_eval_sources(target_wav, est_wav, False)[0][0])\n",
    "\n",
    "    return loss, sdrs_before, sdrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76db7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_forward(model, batch):\n",
    "    criterion = nn.MSELoss()\n",
    "    dvec_mels, target_mag, _, mixed_mag, mixed_phase, _, _, target_wavs, mixed_wavs = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dvec_list = list()\n",
    "        for mel in dvec_mels:\n",
    "            mel = mel.cuda()\n",
    "            dvec = embedder(mel)\n",
    "            dvec_list.append(dvec)\n",
    "        dvec = torch.stack(dvec_list, dim=0)\n",
    "        mixed_mag = mixed_mag.cuda()\n",
    "        target_mag = target_mag.cuda()\n",
    "        \n",
    "        est_mask = model(mixed_mag, dvec)\n",
    "        est_mag = mixed_mag * est_mask\n",
    "        \n",
    "        loss = criterion(target_mag, est_mag).item()\n",
    "\n",
    "        est_mag = est_mag.cpu().numpy()\n",
    "        mixed_phase = mixed_phase.numpy()\n",
    "    \n",
    "    sdrs = []\n",
    "    for est_mag_, mixed_phase_, target_wav in zip(est_mag, mixed_phase, target_wavs):\n",
    "        est_wav = audio.spec2wav(est_mag_, mixed_phase_, length=len(target_wav))\n",
    "        sdrs.append(bss_eval_sources(target_wav, est_wav, False)[0][0])\n",
    "\n",
    "    return loss, sdrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f5255",
   "metadata": {},
   "source": [
    "# Final evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ce088",
   "metadata": {},
   "source": [
    "## GGSpeakerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccff43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 done\n",
      "Step 1 done\n",
      "Step 2 done\n",
      "Step 3 done\n",
      "Step 4 done\n",
      "Step 5 done\n",
      "Step 6 done\n",
      "Step 7 done\n",
      "Step 8 done\n",
      "Step 9 done\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses_p = []\n",
    "losses_0 = []\n",
    "losses_t = []\n",
    "sdrs_before = []\n",
    "sdrs_p = []\n",
    "sdrs_0 = []\n",
    "sdrs_t = []\n",
    "step = 0\n",
    "for batch in testloader_gg:\n",
    "    loss, sdrs_b, sdrs = powerlaw_forward(model, batch)\n",
    "    losses_p.append(loss)\n",
    "    sdrs_before += sdrs_b\n",
    "    sdrs_p += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_0, batch)\n",
    "    losses_0.append(loss)\n",
    "    sdrs_0 += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_t, batch)\n",
    "    losses_t.append(loss)\n",
    "    sdrs_t += sdrs\n",
    "    \n",
    "    print(f\"Step {step} done\")\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GGSpeaker_test.json\", \"w\") as f:\n",
    "    result_json = {\n",
    "        \"losses_p\": losses_p,\n",
    "        \"losses_0\": losses_0,\n",
    "        \"losses_t\": losses_t,\n",
    "        \"sdrs_before\": sdrs_before,\n",
    "        \"sdrs_p\": sdrs_p,\n",
    "        \"sdrs_0\": sdrs_0,\n",
    "        \"sdrs_t\": sdrs_t\n",
    "    }\n",
    "    json_object = json.dumps(result_json, indent = 4)\n",
    "    f.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff527efa",
   "metadata": {},
   "source": [
    "## VN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses_p = []\n",
    "losses_0 = []\n",
    "losses_t = []\n",
    "sdrs_before = []\n",
    "sdrs_p = []\n",
    "sdrs_0 = []\n",
    "sdrs_t = []\n",
    "step = 0\n",
    "for batch in testloader_vn:\n",
    "    loss, sdrs_b, sdrs = powerlaw_forward(model, batch)\n",
    "    losses_p.append(loss)\n",
    "    sdrs_before += sdrs_b\n",
    "    sdrs_p += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_0, batch)\n",
    "    losses_0.append(loss)\n",
    "    sdrs_0 += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_t, batch)\n",
    "    losses_t.append(loss)\n",
    "    sdrs_t += sdrs\n",
    "    \n",
    "    print(f\"Step {step} done\")\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53950621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"VNdata_test.json\", \"w\") as f:\n",
    "    result_json = {\n",
    "        \"losses_p\": losses_p,\n",
    "        \"losses_0\": losses_0,\n",
    "        \"losses_t\": losses_t,\n",
    "        \"sdrs_before\": sdrs_before,\n",
    "        \"sdrs_p\": sdrs_p,\n",
    "        \"sdrs_0\": sdrs_0,\n",
    "        \"sdrs_t\": sdrs_t\n",
    "    }\n",
    "    json_object = json.dumps(result_json, indent = 4)\n",
    "    f.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c0337",
   "metadata": {},
   "source": [
    "## Generate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses_p = []\n",
    "losses_0 = []\n",
    "losses_t = []\n",
    "sdrs_before = []\n",
    "sdrs_p = []\n",
    "sdrs_0 = []\n",
    "sdrs_t = []\n",
    "step = 0\n",
    "for batch in testloader_lb:\n",
    "    loss, sdrs_b, sdrs = powerlaw_forward(model, batch)\n",
    "    losses_p.append(loss)\n",
    "    sdrs_before += sdrs_b\n",
    "    sdrs_p += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_0, batch)\n",
    "    losses_0.append(loss)\n",
    "    sdrs_0 += sdrs\n",
    "\n",
    "    loss, sdrs = mse_forward(model_t, batch)\n",
    "    losses_t.append(loss)\n",
    "    sdrs_t += sdrs\n",
    "    \n",
    "    print(f\"Step {step} done\")\n",
    "    step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Generate_test.json\", \"w\") as f:\n",
    "    result_json = {\n",
    "        \"losses_p\": losses_p,\n",
    "        \"losses_0\": losses_0,\n",
    "        \"losses_t\": losses_t,\n",
    "        \"sdrs_before\": sdrs_before,\n",
    "        \"sdrs_p\": sdrs_p,\n",
    "        \"sdrs_0\": sdrs_0,\n",
    "        \"sdrs_t\": sdrs_t\n",
    "    }\n",
    "    json_object = json.dumps(result_json, indent = 4)\n",
    "    f.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
